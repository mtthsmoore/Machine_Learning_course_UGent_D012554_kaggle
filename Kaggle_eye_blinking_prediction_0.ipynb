{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_eye_blinking_prediciton_0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtthsmoore/Machine_Learning_course_UGent_D012554_kaggle/blob/master/Kaggle_eye_blinking_prediction_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTJvqx22lph8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings;\n",
        "warnings.filterwarnings('ignore');\n",
        "import matplotlib.pyplot as plt;\n",
        "import numpy as np;\n",
        "import pandas as pd;\n",
        "import seaborn as sns;\n",
        "sns.set_context(\"notebook\", font_scale=1.2);\n",
        "sns.set_style(\"whitegrid\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRz1vDATilX5",
        "colab_type": "text"
      },
      "source": [
        "## Normalization of test- and trainingset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob3TifGmlKtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare for modelling\n",
        ".pop(y)\n",
        "#Normalization\n",
        "scaler.fit(trainset)\n",
        "trainset_scaled = scaler.transform(trainset)\n",
        "testset_scaled = scaler.transform(testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcJpPQMuilvz",
        "colab_type": "text"
      },
      "source": [
        "## Model selection\n",
        "Assumptions: binary classification\n",
        "\n",
        "Models: logistic regression, SVM, decision tree -> try with standard hyperparameters and select 2 best performing algorithms for hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxyZDZvqiYbk",
        "colab_type": "text"
      },
      "source": [
        "## Regularization (balance of complexity/degree and good fit/accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpXc9o73qJuo",
        "colab_type": "text"
      },
      "source": [
        "**CROSS-VALIDATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dX2xmvzf0yH",
        "colab_type": "text"
      },
      "source": [
        "Use scikit 10-fold cross-validation to compute estimate of generalization performance of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJijsWJyfvfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "cv_predictions = cross_val_predict(model,X,y,cv=5)\n",
        "print(cv_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hYRcvF4fVyn",
        "colab_type": "text"
      },
      "source": [
        "To optimize the degree $d$ we can now use the CV loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4FV9R_eBmif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset[dataset['folds']==0].copy()\n",
        "y = X.pop('y')\n",
        "folds = X.pop('folds')\n",
        "\n",
        "scores = []\n",
        "scores.append(0) # no features (d=0)\n",
        "cv_predictions = cross_val_predict(model, X, y, cv=5) # (d=1)\n",
        "scores.append(metrics.r2_score(y,cv_predictions)) \n",
        "for degree in range(2,18,1):\n",
        "    X['x1^'+str(degree)] = X['x1']**degree\n",
        "    X['x1^'+str(degree)] = feature_scaler.fit_transform(X[ ['x1^'+str(degree)]])\n",
        "    cv_predictions = cross_val_predict(model, X, y, cv=5) # (d=1)\n",
        "    scores.append(metrics.r2_score(y,cv_predictions)) \n",
        "\n",
        "tmp = pd.DataFrame(scores,columns=['cv_score'])\n",
        "tmp.plot(ylim=(0,1))\n",
        "plt.show()\n",
        "print(\"best CV score: {}\".format(max(scores)))\n",
        "print(\"optimal degree d: {}\".format(np.argmax(scores)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRt0mQS4g2ML",
        "colab_type": "text"
      },
      "source": [
        "Should we consider this best CV score a good estimated of the generalization performance of a model with optimal degree $d$? No. The CV predictions were used to make the decision on the optimal degree $d$. Instead we need a second CV loop that is nested in the first loop to estimate the generalization performance while minimizing the possibility of overfitting. This is called **nested-CV** and will be explained further in this course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naQ5jjWepZIB",
        "colab_type": "text"
      },
      "source": [
        "**TRAIN SET ACCURACY**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuCObIJmqm3w",
        "colab_type": "text"
      },
      "source": [
        "Minimizing the cost function $J(\\theta)$ thus means minimizing the magnitude of the errors made on the data set while minimizing also the complexity of the model (i.e. small values for $\\theta$, preferably zero). The contribution of the model complexity to the cost function is then controlled by **hyperparameter** $\\lambda\\geq0$, which is typically optimized using cross-validation.\n",
        "\n",
        "For regularized logistic regression $\\lambda\\geq0$ is again a model parameter that controls the balance between model training set accuracy and model complexity and is again set by the user. The updates of the model parameters are computed during the gradient descent iterations.\n",
        "\n",
        "For **logistic regression**: Complexity = C = 1/$\\lambda\\$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HwgDo76pEeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Logistic regression without polynomial features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "dataset_clf = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_data/master/notebooks/3_logistic_regression/dataset2D.csv\")\n",
        "\n",
        "X = dataset_clf.copy()\n",
        "y = X.pop('y')\n",
        "model_clf = LogisticRegression(C=10000)\n",
        "model_clf.fit(X,y)\n",
        "\n",
        "#Compute polynomial features for better fit with maximum complexity (overfitting)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "feature_scaler = MinMaxScaler()\n",
        "\n",
        "X = dataset_clf.copy()\n",
        "y = X.pop('y')\n",
        "\n",
        "clf = LogisticRegression(C=1000000)\n",
        "polynomial_features = PolynomialFeatures(degree=7)\n",
        "model_pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
        "                           (\"MinMaxScaler\", feature_scaler),\n",
        "                         (\"logistic_regression\", clf)])\n",
        "\n",
        "model_pipeline.fit(X,y)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plot_decision_boundary(model_pipeline,X,y)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsBaWzG8iLZb",
        "colab_type": "text"
      },
      "source": [
        "We see that the CV performance is optimal for values $C$ arround 50. In this case the average accuracy on the validation sets is 94.2%. However, we cannot consider this accuracy as a performance evaluation of a model with $C=50$. To estimate the performance on unseen external data we have to use an independent test set. However, as the data set is small, leaving out more data might produce unstable results that differ depending on which data points are selected for the test set. \n",
        "\n",
        "To solve this we use cross-validation to create the test set as well. By combining the cross_val_predict() and the GridSearchCV() methods of scikit-learn we can create what is know as a **nested cross-validation** loop to compute the predictions on a test set that contains all the data points in the data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kRtIoI3hnEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#TRAIN SET: Gridsearch: uses cross-validation to find best hyperparameter\n",
        "search_space = np.logspace(-10, 18, 10, base=2)\n",
        "\n",
        "params = dict(logistic_regression__C=search_space)\n",
        "grid_search = GridSearchCV(model_pipeline, param_grid=params)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "means = grid_search.cv_results_['mean_test_score']\n",
        "stds = grid_search.cv_results_['std_test_score']\n",
        "\n",
        "for mean_score, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
        "    print(\"{:.3f} (+/-{:.3f}) for {}\".format(mean_score, std * 2, params))\n",
        "\n",
        "#TEST SET: nested cross-vaidation\n",
        "params = dict(logistic_regression__C=search_space)\n",
        "grid_search = GridSearchCV(model_pipeline, param_grid=params)\n",
        "\n",
        "cv_predictions = cross_val_predict(grid_search, X, y, method=\"predict_proba\")\n",
        "\n",
        "#EXTRA: hyperparameter tuning\n",
        "penalty = ['l1', 'l2']\n",
        "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
        "solver = ['liblinear', 'saga']\n",
        "\n",
        "param_grid = dict(penalty=penalty,\n",
        "                  C=C,\n",
        "                  class_weight=class_weight,\n",
        "                  solver=solver)\n",
        "\n",
        "grid = GridSearchCV(estimator=logistic,\n",
        "                    param_grid=param_grid,\n",
        "                    scoring='roc_auc',\n",
        "                    verbose=1,\n",
        "                    n_jobs=-1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print('Best Score: ', grid_result.best_score_)\n",
        "print('Best Params: ', grid_result.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0125goKRh2B-",
        "colab_type": "text"
      },
      "source": [
        "From these predictions we can now compute an estimate of the generalization performance of our optimal model. Here for instance we compute the AUC:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKhLgYb9hvOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(y, cv_predictions[:,1])\n",
        "print(metrics.auc(fpr, tpr))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}